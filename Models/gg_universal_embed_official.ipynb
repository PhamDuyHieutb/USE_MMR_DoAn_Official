{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "6XivEk74P3ox",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Install the latest Tensorflow version.\n",
    "!pip3 install --quiet \"tensorflow>=1.7\"\n",
    "# Install TF-Hub.\n",
    "!pip3 install --quiet tensorflow-hub\n",
    "!pip3 install --quiet seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "PVjaC2yrJC1Q",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive',  force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "NXePJ_BnJXZL",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!unzip -qq \"/content/gdrive/My Drive/20182_DOAN/universal_embed/data_labels.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "rQrhIeXzQc9j",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "module_url = '/content/gdrive/My Drive/20182_DOAN/universal_embed/model_tf_hub' #\"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "oXYqPmISHmIP",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='/content/gdrive/My Drive/20182_DOAN/universal_embed/weights_20_5_v1.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "def get_dataframe(filedir):\n",
    "    \n",
    "    print(len(os.listdir(filedir)))\n",
    "    data = []\n",
    "    listfilenames = os.listdir(filedir)\n",
    "    for file in listfilenames:\n",
    "        docs = open(filedir + '/' + file, 'r').read().strip().split('\\n####\\n')\n",
    "        for doc in docs:\n",
    "            lines = doc.strip().split('\\n')\n",
    "            lines = [s for s in lines if s != '']\n",
    "            for i in range(0, len(lines)):\n",
    "                label = int(lines[i][0])\n",
    "                text = lines[i][2:]\n",
    "                text = text.replace(\" \\'s\", \"\\'s\")\n",
    "                #text = text.replace(\" \\'d\", \"\\'d\")\n",
    "                #text = text.replace(\" \\'m\", \"\\'m\")\n",
    "                #text = text.replace(\" n\\'t\", \"n\\'t\")\n",
    "                #text = re.sub('[^A-Za-z0-9 ,\\?\\'\\\"-._\\+\\!/\\`@=;:]+', '', text)\n",
    "                data.append([label, text])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['label', 'text'])\n",
    "    df.label = df.label.astype('category')\n",
    "    return df\n",
    "\n",
    "df_train = get_dataframe('/content/train_chunk')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JN7syBJYRGYD",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "train_text = df_train['text'].tolist()\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "category_counts = 2\n",
    "train_label = np.asarray(pd.get_dummies(df_train.label), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "l7nxLCltImRa",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), \n",
    "    \tsignature=\"default\", as_dict=True)[\"default\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "1S25VH-SIpA7",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "input_text = layers.Input(shape=(1,), dtype=\"string\")\n",
    "embedding = layers.Lambda(UniversalEmbedding,\n",
    "\toutput_shape=(512,))(input_text)\n",
    "dense = layers.Dense(256, activation='relu')(embedding)\n",
    "pred = layers.Dense(category_counts, activation='softmax')(dense)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "\toptimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "RvS9560OQm1A",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def get_dataframe_valid(filedir):\n",
    "    list_filenames = os.listdir(filedir)\n",
    "    data = []\n",
    "    for file in list_filenames: \n",
    "        lines = open(filedir + '/' + file, 'r').read().strip().splitlines()\n",
    "        for line in lines:\n",
    "            label = int(line[0])\n",
    "            text = line[2:]\n",
    "            text = text.replace(\" \\'s\", \"\\'s\")\n",
    "            #text = text.replace(\" \\'d\", \"\\'d\")\n",
    "            #text = text.replace(\" \\'m\", \"\\'m\")\n",
    "            #text = text.replace(\" n\\'t\", \"n\\'t\")\n",
    "            #text = re.sub('[^A-Za-z0-9 ,\\?\\'\\\"-._\\+\\!/\\`@=;:]+', '', text)\n",
    "            data.append([label, text])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['label', 'text'])\n",
    "    df.label = df.label.astype('category')\n",
    "    return df\n",
    "\n",
    "df_test = get_dataframe_valid('/content/valid')\n",
    "test_text = df_test['text'].tolist()\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "test_label = np.asarray(pd.get_dummies(df_test.label), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ZFU0tCbaIrm6",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  history = model.fit(train_text, \n",
    "            train_label,\n",
    "            validation_data=(test_text, test_label),\n",
    "            epochs=12,\n",
    "            batch_size=50,\n",
    "            callbacks=[checkpointer])\n",
    "  \n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training loss', 'valid loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "C7OgN67QIzjz",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "filedir = '/content/test'\n",
    "def get_dataframe_test(filename):\n",
    "    data = []\n",
    "    lines = open(filedir + '/' + filename, 'r').read().strip().split('\\n')\n",
    "    lines = [line for line in lines if line != '']\n",
    "    for line in lines:\n",
    "        label = int(line[0])\n",
    "        text = line[2:]\n",
    "        text = re.sub('[^A-Za-z0-9 ,\\?\\'\\\"-._\\+\\!/\\`@=;:]+', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = text.replace(\" \\'s\", \"\\'s\")\n",
    "        text = text.replace(\" \\'d\", \"\\'d\")\n",
    "        text = text.replace(\" \\'m\", \"\\'m\")\n",
    "        text = text.replace(\" n\\'t\", \"n\\'t\")\n",
    "        if text != ' ':\n",
    "            data.append([label, text])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['label', 'text'])\n",
    "    df.label = df.label.astype('category')\n",
    "    return df\n",
    "\n",
    "\n",
    "list_test_filenames = os.listdir(filedir)\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    model1 = Model(inputs=[input_text], outputs=pred)\n",
    "    model1.load_weights('/content/gdrive/My Drive/20182_DOAN/universal_embed/weights_24_4.hdf5')  \n",
    "    model1.compile(loss='categorical_crossentropy', \n",
    "    optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    for file in list_test_filenames:\n",
    "        try:\n",
    "            print(file)\n",
    "            df_test = get_dataframe_test(file)\n",
    "            new_text = df_test['text'].tolist()\n",
    "            new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "            #test_label = np.asarray(pd.get_dummies(df_test.label), dtype = np.int8)\n",
    "          \n",
    "            predicts = model1.predict(new_text, batch_size=80)\n",
    "            print(len(new_text), len(predicts))\n",
    "            np.save('/content/gdrive/My Drive/20182_DOAN/universal_embed/test_prob/' + file + '.npy', predicts)\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "O4MmZHe5-fl7",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!zip -r '/content/test_prob_24.zip' '/content/gdrive/My Drive/20182_DOAN/universal_embed/test_prob'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "gg_universal_embed_test_visual.ipynb",
   "version": "0.3.2",
   "provenance": [
    {
     "file_id": "1ZgGRQ_LozMQWvcWCPyxCrguFro-V_KUN",
     "timestamp": 1.556097903489E12
    },
    {
     "file_id": "1xOk0DYmTooyU_VAAxyr4-4c2UrvkTZf_",
     "timestamp": 1.555743873268E12
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
